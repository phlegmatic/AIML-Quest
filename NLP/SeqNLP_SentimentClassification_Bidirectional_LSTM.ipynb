{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xT7MKZuMRaCg"
   },
   "source": [
    "# Sentiment Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description:\n",
    "\n",
    "Generate Word Embeddingand retrieve outputs of each layer with Keras based on the Classification task.\n",
    "Word embeddingare a type of word representation that allows words with similar meaning to have a similar representation.\n",
    "It is a distributed representation for the text that is perhaps one of the key breakthroughs for the impressive \n",
    "performance of deep learning methods on challenging natural language processing problems.\n",
    "We will use the IMDb dataset to learn word embeddingas we train our dataset. \n",
    "This dataset contains 25,000 movie reviews from IMDB, labeled with a sentiment (positive or negative).\n",
    "\n",
    "\n",
    "## Data Description:\n",
    "The Dataset of 25,000 movie reviews from IMDB, labeled by sentiment (positive/negative). \n",
    "Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). \n",
    "For convenience, the words are indexed by their frequency in the dataset, \n",
    "meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, \n",
    "using a max vocab size of 10,000.As a convention, \"0\" does not stand for a specific word, but instead is used to \n",
    "encode any unknown word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wq4RCyyPSYRp"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGCtiXUhSWss"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "vocab_size = 10000 #vocab size\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size) # vocab_size is no.of words to consider from the dataset, ordering based on frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fCPC_WN-eCyw"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "vocab_size = 10000 #vocab size\n",
    "maxlen = 30  #number of word used from each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qMEsHYrWxdtk"
   },
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sYcsPdlrsBwh",
    "outputId": "9608e039-0ebf-4f0a-fa2d-1dac54f4aad8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0g381XzeCyz"
   },
   "outputs": [],
   "source": [
    "#make all sequences of the same length\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen,padding='post')\n",
    "x_test =  pad_sequences(x_test, maxlen=maxlen,padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "boFV57RUg0hO",
    "outputId": "8b48d89f-d6fd-465e-d7c5-08134c0bedae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 30) (25000,)\n",
      "(25000, 30) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "wP8vwE5qg-Se",
    "outputId": "4b0852e7-f7ec-4a4b-d1cd-d81ca8ec6a9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  18,   51,   36,   28,  224,   92,   25,  104,    4,  226,   65,\n",
       "         16,   38, 1334,   88,   12,   16,  283,    5,   16, 4472,  113,\n",
       "        103,   32,   15,   16, 5345,   19,  178,   32], dtype=int32)"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IOo046Hsf3X_",
    "outputId": "fe94ee5f-a822-4a35-bb75-75cf583ce026"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pkd1fCR2RedS",
    "outputId": "7dbf2fe5-286a-4323-9614-c6b225fc4661"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88584"
      ]
     },
     "execution_count": 79,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get the word index and then Create a key-value pair for word and word_id\n",
    "word_index = imdb.get_word_index()\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "CoTYfwyKRk3y",
    "outputId": "44684205-5761-4661-8927-acfc2ff0461a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict(\n",
    "[(value, key) for (key, value) in word_index.items()])\n",
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_train[1]])\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dybtUgUReCy8"
   },
   "source": [
    "## Build Keras Embedding Layer Model\n",
    "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
    "\n",
    "* The embedding layer can be used at the start of a larger deep learning model. \n",
    "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
    "* Use the embedding layer to train our own word2vec models.\n",
    "\n",
    "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 372
    },
    "colab_type": "code",
    "id": "A5OLM4eBeCy9",
    "outputId": "2bc8cc89-c093-4568-ab9c-857a82ca70f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 20)          200000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 20)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 600)               770400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 971,001\n",
      "Trainable params: 971,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout,Bidirectional\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,output_dim=20))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Bidirectional(LSTM(units = 300, dropout=0.1, recurrent_dropout=0.2)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFLBmNUDh86M"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "TxNDNhrseCzA",
    "outputId": "072873db-11ee-4d11-b685-4e592f05ed81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.5776 - accuracy: 0.6776 - val_loss: 0.4551 - val_accuracy: 0.7841\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 14s 110ms/step - loss: 0.4048 - accuracy: 0.8170 - val_loss: 0.4697 - val_accuracy: 0.7874\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 14s 110ms/step - loss: 0.3386 - accuracy: 0.8535 - val_loss: 0.4790 - val_accuracy: 0.7800\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 14s 111ms/step - loss: 0.2944 - accuracy: 0.8772 - val_loss: 0.5022 - val_accuracy: 0.7720\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.2658 - accuracy: 0.8902 - val_loss: 0.6166 - val_accuracy: 0.7614\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.2358 - accuracy: 0.9032 - val_loss: 0.5457 - val_accuracy: 0.7635\n",
      "Epoch 00006: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe41cebb6d8>"
      ]
     },
     "execution_count": 84,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 200\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=10,  validation_data=(x_test, y_test), verbose=1, callbacks = [es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Igq8Qm8GeCzG"
   },
   "source": [
    "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-dUDSg7VeCzM"
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "D4teWY_7DOo5",
    "outputId": "086c1347-c062-43ab-c447-a286b781697b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8692282], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tskt_1npeCzP"
   },
   "outputs": [],
   "source": [
    "#rounding off \n",
    "import numpy as np\n",
    "y_predr = []\n",
    "for i in range(len(y_pred)):\n",
    "    y_predr.append(np.round(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "GMmtxSE--YZW",
    "outputId": "24b87105-8184-4960-d5f4-30e06ce461aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "\n",
      "               pred:negative  pred:postive\n",
      "true:negative           9935          2565\n",
      "true:postive            3347          9153\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77     12500\n",
      "           1       0.78      0.73      0.76     12500\n",
      "\n",
      "    accuracy                           0.76     25000\n",
      "   macro avg       0.76      0.76      0.76     25000\n",
      "weighted avg       0.76      0.76      0.76     25000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9935, 2565],\n",
       "       [3347, 9153]])"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_predr, labels=[0, 1]), index=['true:negative', 'true:postive'], columns=['pred:negative', 'pred:postive']))\n",
    "print(metrics.classification_report(y_test, y_predr))\n",
    "confusion_matrix(y_test, y_predr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yADd5GrzxKic"
   },
   "outputs": [],
   "source": [
    "# Retrive the output of each layer in keras for a given single test sample from the trained model you built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fOhXWNHjE3tL"
   },
   "outputs": [],
   "source": [
    "#Fetching 28 the record\n",
    "testRecord = np.array([x_test[20]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wwcgNimjFb72",
    "outputId": "9ddc63fe-069d-4f55-ed0d-da1f459f8113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turns this film will leave you ? i found the cast of this movie to be outstanding and is not a movie to be ignored excellent go rent it today\n"
     ]
    }
   ],
   "source": [
    "decoded_review = ' '.join([reverse_word_index.get(i - 3, '?') for i in x_test[20]])\n",
    "print(decoded_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7ceM6HnfFoYK",
    "outputId": "77fe8c7e-299b-4a2a-ea1d-8c6bc94e0be0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of layer1: [[[-4.65203896e-02  1.86735447e-02 -1.95319410e-02  1.00971468e-01\n",
      "   -1.04768788e-02 -2.18674708e-02 -9.91381798e-03 -4.53054197e-02\n",
      "    7.10829999e-03 -7.40332603e-02 -5.32241091e-02  3.22945183e-04\n",
      "   -3.88734159e-03  3.85249257e-02  1.92133486e-02 -1.00648247e-01\n",
      "    4.48713899e-02  2.97793304e-06 -2.11031139e-02  4.11805399e-02]\n",
      "  [ 1.42734321e-02 -2.33644564e-02  2.24801265e-02  4.42969054e-02\n",
      "    3.45924161e-02 -3.09708472e-02 -3.48970816e-02 -2.38658953e-02\n",
      "    1.54063879e-02 -7.47941155e-03 -1.20499684e-02 -3.06876730e-02\n",
      "   -1.69527121e-02 -4.00346741e-02 -1.02210455e-02 -2.55237650e-02\n",
      "    7.13019213e-03  3.09951752e-02  1.23121487e-02  1.80029664e-02]\n",
      "  [ 8.84205196e-03  2.17464529e-02  3.91567498e-03  4.95414436e-03\n",
      "   -3.97935919e-02 -9.97586641e-03 -2.23667664e-03  1.63233969e-02\n",
      "   -8.65611713e-03 -1.11917891e-02  2.75000166e-02 -5.25040813e-02\n",
      "    1.55943343e-02  1.16423226e-03  1.82386767e-02  3.78081612e-02\n",
      "    1.89039838e-02  8.80999397e-03 -2.08546761e-02 -2.45891418e-02]\n",
      "  [-5.18374220e-02  1.52073465e-02  2.05536466e-02  3.84129696e-02\n",
      "   -3.92035358e-02  4.67746817e-02 -1.30194947e-02  1.24037052e-02\n",
      "    2.10712794e-02  6.81536272e-03 -6.24181179e-04  4.75394540e-03\n",
      "    2.70229168e-02 -1.06485905e-02  2.91938614e-02 -4.04033400e-02\n",
      "   -2.98991520e-02  1.03982650e-02  1.64657403e-02 -1.03111919e-02]\n",
      "  [ 2.96310876e-02 -7.91156217e-02 -8.32537338e-02 -2.07936093e-02\n",
      "    5.27926870e-02 -3.15545835e-02  4.06719372e-02  6.71117008e-02\n",
      "    1.17518045e-01  5.96077694e-03 -3.34335044e-02 -9.38875880e-03\n",
      "    1.48155428e-02  1.00468788e-02 -6.21253103e-02  8.25048015e-02\n",
      "   -4.79886532e-02 -2.53010131e-02 -4.20851726e-03 -4.21334989e-03]\n",
      "  [-6.17633089e-02  2.17930656e-02  6.43664896e-02  1.56626087e-02\n",
      "   -1.94174424e-02  2.17705350e-02  2.16045380e-02  1.54354824e-02\n",
      "   -1.10076498e-02 -1.02262301e-02 -3.47647741e-02  2.76873093e-02\n",
      "   -2.42169499e-02  1.05710337e-02 -8.57967231e-03 -1.22713465e-02\n",
      "    1.26635190e-03 -2.81988308e-02  1.04429387e-02 -1.69992764e-02]\n",
      "  [ 5.48261916e-03 -1.57527216e-02 -6.19055703e-03 -1.22324200e-02\n",
      "    2.14101677e-03  5.80319017e-03 -9.66716465e-03 -2.16047019e-02\n",
      "    5.05408552e-03 -5.15493914e-04 -1.54808629e-03 -2.61096023e-02\n",
      "    2.61671040e-02 -7.22864736e-03  3.94998351e-03  1.38999261e-02\n",
      "    2.93875635e-02  3.93812358e-03  2.56430488e-02 -7.45710125e-03]\n",
      "  [ 8.54754588e-04  3.12948041e-02  2.04800628e-02  4.51900810e-03\n",
      "   -6.66301884e-03  2.25713905e-02  2.30654273e-02  3.26658450e-02\n",
      "   -3.27369547e-04  2.08920669e-02 -1.12610986e-03 -5.13606472e-03\n",
      "   -3.77455205e-02  5.50961075e-03 -1.94505882e-02  1.31175527e-02\n",
      "   -1.80085059e-02 -1.41994643e-03 -3.57498378e-02  4.07860391e-02]\n",
      "  [ 2.56714318e-02 -3.92362736e-02 -3.90056744e-02 -8.60567018e-03\n",
      "   -1.79478433e-02  1.90418605e-02  2.26212735e-03 -1.25799580e-02\n",
      "   -3.17599461e-03 -2.93524265e-02  2.22206470e-02  1.26409512e-02\n",
      "   -1.84399523e-02 -6.05634190e-02  8.97652004e-03  7.79394582e-02\n",
      "    3.45192812e-02  1.11070005e-02  3.26032229e-02  4.98514250e-02]\n",
      "  [ 1.75945945e-02  1.08309751e-02  2.99532879e-02  2.20204685e-02\n",
      "    2.12606825e-02  7.09792366e-03 -9.89322551e-03 -2.59449612e-02\n",
      "   -1.74265523e-02 -5.95102832e-03 -8.99501983e-03  3.01071350e-02\n",
      "    2.66868845e-02 -1.11309057e-02 -1.57091711e-02  1.10568684e-02\n",
      "    1.04025158e-03  2.25877687e-02 -1.80177912e-02  1.48588317e-02]\n",
      "  [ 1.82681996e-02  7.01926323e-03  1.03351837e-02  1.17877610e-02\n",
      "    4.03804518e-02  2.34626886e-02  2.02125357e-03  1.51578560e-02\n",
      "    4.41364087e-02 -4.78599630e-02  2.01145280e-02 -5.07633239e-02\n",
      "   -1.83773842e-02  1.52725959e-02  4.40046526e-02  2.40211226e-02\n",
      "    1.50492014e-02  2.14294810e-02  4.36262041e-02  3.97708006e-02]\n",
      "  [-1.67302340e-02 -1.74948685e-02 -2.24918040e-04 -2.19698362e-02\n",
      "    1.68372206e-02 -1.41340476e-02  1.72600523e-02 -3.40772723e-03\n",
      "   -5.23628527e-03 -1.60163864e-02  1.64077487e-02  2.10537724e-02\n",
      "    1.89121673e-03  1.56775825e-02 -1.54157951e-02  4.32174131e-02\n",
      "    7.67541025e-03  1.06294388e-02 -7.16114976e-03  7.93193094e-03]\n",
      "  [ 1.42734321e-02 -2.33644564e-02  2.24801265e-02  4.42969054e-02\n",
      "    3.45924161e-02 -3.09708472e-02 -3.48970816e-02 -2.38658953e-02\n",
      "    1.54063879e-02 -7.47941155e-03 -1.20499684e-02 -3.06876730e-02\n",
      "   -1.69527121e-02 -4.00346741e-02 -1.02210455e-02 -2.55237650e-02\n",
      "    7.13019213e-03  3.09951752e-02  1.23121487e-02  1.80029664e-02]\n",
      "  [ 8.41901638e-03 -1.94608551e-02  3.56453955e-02  1.60069298e-02\n",
      "    2.62987334e-02  1.95250788e-04 -3.72094437e-02  3.73886563e-02\n",
      "    8.71812087e-03  3.11595909e-02  5.57065895e-03 -1.80354007e-02\n",
      "    6.80326205e-03  5.93506871e-03 -2.48227734e-02 -1.24481013e-02\n",
      "    4.80310852e-03 -2.53644176e-02 -1.12153124e-02  1.05481772e-02]\n",
      "  [ 1.25245908e-02  4.66285134e-03 -8.74694670e-04 -4.99266991e-03\n",
      "    1.10359108e-02 -4.48900554e-03 -3.39099914e-02  1.35056609e-02\n",
      "   -1.64985694e-02  2.49484517e-02  2.50994973e-02 -9.15260147e-03\n",
      "    2.68804785e-02 -1.76420575e-03  2.18915362e-02 -4.18276079e-02\n",
      "   -5.05686970e-03 -7.65017280e-03 -8.90926830e-03  2.72289086e-02]\n",
      "  [ 7.20565114e-03  2.43093148e-02 -1.16798701e-02 -4.26923148e-02\n",
      "    1.54049955e-02 -2.19941307e-02 -2.56316215e-02 -4.28744331e-02\n",
      "   -1.07296705e-02 -5.65545447e-03  2.34487504e-02  3.55993100e-02\n",
      "   -7.57134811e-04  2.36483961e-02 -2.23965794e-02 -9.95665789e-03\n",
      "   -1.77061446e-02 -2.50397380e-02 -3.39994789e-04  5.85137419e-02]\n",
      "  [-9.11668614e-02  9.78857800e-02  2.04316322e-02  4.74408902e-02\n",
      "   -5.54856323e-02  4.67150956e-02 -1.03883613e-02 -2.66300119e-03\n",
      "   -5.32725528e-02  2.58964151e-02  2.97836196e-02  7.38010406e-02\n",
      "   -8.94364268e-02  4.48527150e-02  8.17701891e-02 -4.10121344e-02\n",
      "    6.73850477e-02  1.31969471e-02 -4.93318439e-02  4.62259501e-02]\n",
      "  [-2.57524159e-02  3.98594048e-03  3.44346054e-02 -3.81431617e-02\n",
      "    2.47566737e-02 -7.37036718e-03 -3.26999910e-02 -1.40950521e-02\n",
      "   -2.94338763e-02 -2.61265337e-02  1.90242508e-03  3.65470126e-02\n",
      "   -1.34688467e-02  6.94053480e-03  2.52119941e-03 -1.46213295e-02\n",
      "   -2.58218944e-02 -1.79016776e-02 -3.50244902e-02  2.30276529e-02]\n",
      "  [-3.18042189e-02  2.57692896e-02 -1.86466612e-02 -2.19070315e-02\n",
      "    1.72029808e-02 -2.37331755e-04  5.02328062e-03  9.82940756e-03\n",
      "    1.64422989e-02  4.02146298e-03  9.36701987e-03  2.53845826e-02\n",
      "   -1.83188468e-02  1.96726471e-02  7.24688312e-03 -3.03660221e-02\n",
      "    1.85597371e-02 -1.70227084e-02 -2.35818699e-02  3.14811170e-02]\n",
      "  [ 2.58094762e-02 -2.55288556e-02 -5.02992608e-02 -3.21743935e-02\n",
      "    1.01408297e-02 -1.11536123e-02  3.11383624e-02  7.41594750e-03\n",
      "    2.71627773e-02 -3.11843771e-03 -6.91154674e-02 -2.09829472e-02\n",
      "   -5.89024927e-03 -1.07748639e-02 -1.03912093e-02  5.17096259e-02\n",
      "   -4.61151591e-04  2.85884086e-02  6.01796508e-02 -5.96929621e-03]\n",
      "  [-1.56446602e-02 -1.19622471e-02  2.21220553e-02  4.74664988e-03\n",
      "    3.64742279e-02  2.28607226e-02 -3.64485495e-02 -3.30803134e-02\n",
      "    3.77999321e-02 -5.34598529e-03  1.15099363e-03 -2.98499074e-02\n",
      "   -8.68146191e-04  1.09399976e-02  1.43121798e-02 -1.24421762e-03\n",
      "   -2.39698254e-02 -2.99381204e-02 -4.60381294e-03 -4.03787903e-02]\n",
      "  [ 8.41901638e-03 -1.94608551e-02  3.56453955e-02  1.60069298e-02\n",
      "    2.62987334e-02  1.95250788e-04 -3.72094437e-02  3.73886563e-02\n",
      "    8.71812087e-03  3.11595909e-02  5.57065895e-03 -1.80354007e-02\n",
      "    6.80326205e-03  5.93506871e-03 -2.48227734e-02 -1.24481013e-02\n",
      "    4.80310852e-03 -2.53644176e-02 -1.12153124e-02  1.05481772e-02]\n",
      "  [ 1.25245908e-02  4.66285134e-03 -8.74694670e-04 -4.99266991e-03\n",
      "    1.10359108e-02 -4.48900554e-03 -3.39099914e-02  1.35056609e-02\n",
      "   -1.64985694e-02  2.49484517e-02  2.50994973e-02 -9.15260147e-03\n",
      "    2.68804785e-02 -1.76420575e-03  2.18915362e-02 -4.18276079e-02\n",
      "   -5.05686970e-03 -7.65017280e-03 -8.90926830e-03  2.72289086e-02]\n",
      "  [ 7.20565114e-03  2.43093148e-02 -1.16798701e-02 -4.26923148e-02\n",
      "    1.54049955e-02 -2.19941307e-02 -2.56316215e-02 -4.28744331e-02\n",
      "   -1.07296705e-02 -5.65545447e-03  2.34487504e-02  3.55993100e-02\n",
      "   -7.57134811e-04  2.36483961e-02 -2.23965794e-02 -9.95665789e-03\n",
      "   -1.77061446e-02 -2.50397380e-02 -3.39994789e-04  5.85137419e-02]\n",
      "  [-3.49897332e-02 -2.48156860e-02  4.22402285e-02 -3.97064723e-02\n",
      "    2.49395519e-02  1.00160558e-02  5.50475381e-02  6.27819868e-03\n",
      "   -5.86202443e-02  5.43131381e-02  1.55611448e-02  7.07603619e-02\n",
      "   -1.37724839e-02 -8.76479689e-03  3.63209881e-02 -4.56320941e-02\n",
      "   -4.73947749e-02  3.54035236e-02 -4.60787909e-03 -1.94805525e-02]\n",
      "  [-3.90684232e-02  9.48806852e-02  1.10397652e-01  7.99986050e-02\n",
      "   -1.26697123e-01  1.20211259e-01 -4.94287834e-02 -1.11784808e-01\n",
      "   -2.98332404e-02  4.86770505e-03  1.98697597e-02  7.23472759e-02\n",
      "   -7.88342059e-02  1.15236610e-01  7.18714148e-02 -7.79521689e-02\n",
      "    4.50369641e-02 -5.95376752e-02 -1.05574161e-01  7.75366947e-02]\n",
      "  [ 2.90990807e-02 -4.80437092e-03 -2.22597038e-03  3.98653336e-02\n",
      "    2.66311672e-02  3.82892638e-02  1.83050334e-02 -1.67413114e-03\n",
      "   -3.24029708e-03 -4.00165431e-02  4.05048653e-02 -2.02985834e-02\n",
      "   -8.05176329e-03  3.36067937e-02 -1.96208730e-02 -2.27358248e-02\n",
      "    1.52858635e-02 -1.77406520e-03 -3.73443738e-02  5.20191640e-02]\n",
      "  [ 5.02802841e-02 -1.38346609e-02 -3.56638990e-02 -3.55785601e-02\n",
      "    6.87957034e-02 -1.89650431e-02  8.71631503e-02  2.33361032e-02\n",
      "    2.53389496e-02  5.54114915e-02  2.14973874e-02 -1.07667986e-02\n",
      "    8.34303498e-02 -1.41789541e-02 -9.28797759e-03  3.33437137e-02\n",
      "   -2.85968147e-02  2.36741472e-02  8.42037424e-03 -6.80012032e-02]\n",
      "  [-1.94645599e-02  3.36578786e-02  2.27887575e-02 -5.96960960e-03\n",
      "   -3.64172719e-02  2.28187349e-02 -1.48834037e-02  4.25813673e-03\n",
      "   -2.73472238e-02 -1.61789320e-02  5.33080101e-03 -2.01130714e-02\n",
      "   -3.43807265e-02 -1.73532665e-02 -1.31925801e-03 -2.81850547e-02\n",
      "   -1.67558920e-02 -1.75232384e-02 -5.91754029e-03  3.70482691e-02]\n",
      "  [-6.08612746e-02  4.61347401e-02  1.06217384e-01  1.11840554e-01\n",
      "   -7.70726101e-03  1.12834670e-01 -4.16688211e-02 -6.21577166e-02\n",
      "   -6.01993687e-02 -4.35621217e-02  2.13705469e-02  2.19356958e-02\n",
      "   -6.85388744e-02  3.54772620e-02  6.73796684e-02 -3.66215669e-02\n",
      "   -1.87342812e-03 -8.22895244e-02 -1.06889293e-01  1.04786336e-01]]]\n",
      "Output of layer2: [[-6.87326342e-02 -5.27940616e-02 -5.72142862e-02 -1.93900485e-02\n",
      "  -4.28360701e-03 -1.06401909e-02  1.60823651e-02  8.62326995e-02\n",
      "   7.70907430e-03 -1.59117788e-01 -2.04999149e-02 -5.28576858e-02\n",
      "  -8.79375264e-03 -5.80392254e-04  1.37562811e-01 -8.45649373e-03\n",
      "  -3.82578783e-02  1.33446325e-02 -4.00171839e-02 -1.66204087e-02\n",
      "  -1.09391445e-02 -4.51857364e-03  2.95156203e-02 -9.46677849e-03\n",
      "   1.17541756e-03 -1.47087201e-02  1.09966588e-03 -9.55737531e-02\n",
      "   2.40552742e-02  2.59368622e-04 -6.31850809e-02  1.14888083e-02\n",
      "  -4.08317568e-03 -6.87701860e-03  2.38102227e-02  5.05348807e-03\n",
      "   1.11943055e-02  4.56089387e-03 -8.47547967e-03 -1.95412133e-02\n",
      "  -4.56956252e-02 -1.25915268e-02  1.04054501e-02 -4.71264310e-02\n",
      "  -3.98979802e-03 -1.46064106e-02 -5.85746648e-07  1.35023087e-01\n",
      "  -6.39683530e-02  5.77096222e-03 -1.12778552e-01 -8.22099447e-02\n",
      "  -4.91003543e-02 -1.45946760e-02  2.67972369e-02  2.38571912e-02\n",
      "   1.16607979e-01 -8.05808790e-03 -4.07995097e-03 -1.86783578e-02\n",
      "   4.73717861e-02  1.02160210e-02 -4.42813151e-03 -1.11611867e-02\n",
      "   1.34597063e-01  1.20797558e-02 -2.33214651e-03 -6.24043122e-03\n",
      "   1.39901778e-02  3.15955072e-03 -4.50118491e-03 -2.97527518e-02\n",
      "   6.11127960e-03 -1.27067342e-01  3.66163328e-02 -8.34419392e-03\n",
      "   2.01207176e-02  5.45140356e-02  1.47984162e-01  3.24229710e-02\n",
      "   3.09652239e-02 -2.50512231e-02 -2.20823623e-02  8.47932324e-03\n",
      "  -5.08979410e-02  6.72802031e-02 -1.76837854e-02  8.36523250e-03\n",
      "  -6.70827851e-02 -2.60275137e-02 -9.33677424e-04 -9.62063521e-02\n",
      "  -9.06630233e-03  1.50967985e-01 -4.64809453e-03  1.49585053e-01\n",
      "  -1.24636637e-02 -3.00471652e-02  6.59249499e-02 -4.00722139e-02\n",
      "  -5.45423180e-02  2.63713617e-02  1.22038450e-03 -1.25507256e-02\n",
      "  -1.08590066e-01 -5.27107576e-03 -6.76162029e-03  3.33772041e-02\n",
      "  -6.23703329e-03 -9.81528014e-02 -1.13985585e-02 -8.23196606e-04\n",
      "   4.16772291e-02  3.13525796e-02 -8.19574576e-03  5.43150725e-03\n",
      "  -1.41507134e-01 -5.90341073e-03  1.29561834e-02 -1.68620534e-02\n",
      "  -5.32630924e-03 -7.96706900e-02 -1.94487888e-02 -8.63234848e-02\n",
      "   3.81655842e-02  5.08508757e-02 -6.73146825e-03 -2.89527625e-02\n",
      "   8.55111778e-02 -2.68942234e-03  1.09185334e-02 -1.16156749e-02\n",
      "   7.35618873e-03 -9.07112565e-03 -4.12505455e-02  1.73074454e-01\n",
      "   5.18823154e-02 -8.63083079e-02  7.86386356e-02 -4.63328771e-02\n",
      "  -1.06731474e-01 -2.88770702e-02 -1.04895398e-01 -3.26075628e-02\n",
      "   2.28380063e-03  5.18546859e-03  2.10758746e-02  1.24236591e-01\n",
      "  -3.37072238e-02  1.07195705e-01 -1.45785082e-02 -1.50719583e-01\n",
      "  -2.11980771e-02 -1.51058554e-03 -2.33550817e-02  3.43761705e-02\n",
      "   8.40286463e-02  1.99319720e-02 -1.28702363e-02 -1.07702054e-01\n",
      "   1.34769743e-02  1.48231927e-02  1.75693318e-01  1.10218033e-01\n",
      "   1.19306296e-01 -1.69324540e-02 -1.87276639e-02 -6.55514598e-02\n",
      "   9.34027834e-04 -1.33786201e-01  1.84586812e-02 -3.45847942e-02\n",
      "  -2.09442733e-04  1.66744217e-02 -7.05156894e-03  4.03821468e-03\n",
      "   8.35802592e-03 -1.43794671e-01 -4.68538292e-02 -6.24411069e-02\n",
      "   1.21855401e-02 -1.65118754e-03 -4.21961397e-02 -6.59202132e-03\n",
      "  -7.27202930e-03 -7.21346587e-02 -1.47260753e-02  2.02361681e-02\n",
      "  -4.37645288e-03  8.05849954e-03  6.43877219e-03 -9.62416641e-03\n",
      "  -3.73924337e-03 -3.99219356e-02  1.18247092e-01 -3.50329131e-02\n",
      "   5.92288096e-03  9.95035470e-02 -2.07698606e-02 -1.89392596e-01\n",
      "  -8.35657790e-02  2.67721470e-02  1.18072368e-02  1.18379526e-01\n",
      "   1.92253137e-04 -9.68668424e-03 -5.03852917e-03  1.41262133e-02\n",
      "  -1.15148509e-02  1.51689008e-01 -6.67274091e-03 -1.13964990e-01\n",
      "   7.15964846e-03 -3.49008664e-02 -8.76068044e-03  9.99207608e-03\n",
      "  -1.19243287e-01 -6.31976500e-02  6.81818137e-03 -2.57478748e-02\n",
      "  -1.36027008e-03 -2.47236956e-02  1.02810860e-02 -7.21430639e-03\n",
      "  -3.04248165e-02 -2.30807401e-02 -6.43680915e-02  1.28673064e-03\n",
      "   2.57778838e-02 -7.16053043e-03 -4.82717268e-02  2.35875193e-02\n",
      "  -4.53231810e-03 -4.44149934e-02 -8.55540484e-02  1.93116104e-03\n",
      "   1.50594890e-01 -1.70283034e-01  1.19646296e-01  5.03577711e-03\n",
      "  -3.96525860e-02  1.80234816e-02  9.13191400e-03  6.73069758e-03\n",
      "   2.13196245e-03  7.80503033e-04  2.19819252e-03  6.30540075e-03\n",
      "  -1.08979471e-01  1.67747512e-01 -4.78564464e-02 -5.16997129e-02\n",
      "  -2.99299490e-02 -2.38355491e-02 -1.14213172e-02 -2.02176049e-02\n",
      "   9.75443237e-03 -6.45943265e-03 -1.09302260e-01 -1.15637682e-01\n",
      "   4.70501296e-02  2.25005057e-02  5.63047454e-03 -1.48874521e-01\n",
      "  -5.41088078e-03  8.12216103e-02  6.95356913e-03  1.82675451e-01\n",
      "  -8.77346261e-04  2.34128162e-02 -1.19599111e-01 -2.43659830e-03\n",
      "   1.59013122e-01  1.16890289e-01  9.48609595e-05 -2.22146921e-02\n",
      "   2.18317262e-03 -1.31745964e-01 -2.51869280e-02 -4.88150772e-03\n",
      "   2.85312086e-02  1.13351280e-02  1.26630813e-02 -8.79008137e-03\n",
      "   1.60219278e-02  4.11272794e-02 -5.73797449e-02  7.51548796e-04\n",
      "   1.05898857e-01  6.84850439e-02 -8.11873227e-02 -2.44119689e-02\n",
      "   2.59437191e-04 -1.56009719e-01  4.51276498e-03 -2.79741711e-03\n",
      "   8.79131351e-03  2.83476487e-02 -1.41328707e-01 -1.12378756e-02\n",
      "   1.68909095e-02  6.44232985e-03 -3.48291546e-01  1.08246155e-01\n",
      "  -4.02798086e-01 -1.30963549e-01 -2.11645849e-02 -1.70753926e-01\n",
      "   1.08112572e-02  2.65640300e-02 -1.90296490e-02  1.72161032e-02\n",
      "  -1.38499103e-02  3.11165363e-01 -1.90426577e-02 -1.92924831e-02\n",
      "   9.32893809e-03 -2.58719176e-01 -1.40754571e-02 -1.20148798e-02\n",
      "  -4.79779905e-03 -1.07814800e-02  3.37848738e-02  1.30954823e-02\n",
      "  -2.54938304e-01  2.99957782e-01 -1.91979051e-01 -1.32001624e-01\n",
      "  -1.25223268e-02 -4.31262888e-02 -7.57429004e-03  1.04305625e-01\n",
      "  -3.92480381e-03  2.99242348e-03 -4.63690609e-02  4.11275685e-01\n",
      "   5.06219268e-01  4.00006264e-01 -2.12523304e-02  2.68988870e-02\n",
      "  -5.83460443e-02  7.62244826e-03  1.11274511e-01  1.88771859e-02\n",
      "  -6.79051084e-03 -7.79603124e-02  2.04067275e-01  1.21345066e-01\n",
      "  -1.00031281e-02 -1.16681857e-02 -8.09348933e-03 -1.64147243e-01\n",
      "   2.50856519e-01  3.57411895e-03 -9.72614214e-02 -1.29631096e-02\n",
      "  -1.15562277e-02 -7.75724500e-02  2.06074193e-02 -3.28959048e-01\n",
      "   2.19262671e-02 -2.48930186e-01 -1.83923673e-02 -3.57279301e-01\n",
      "  -6.33823514e-01  3.46937159e-04  2.22335965e-03  9.24548414e-03\n",
      "  -8.61379597e-03  3.99558425e-01  1.89068049e-01 -6.34913743e-02\n",
      "   1.50742576e-01 -3.78394455e-01  3.87435593e-03 -3.88707966e-01\n",
      "   3.46665412e-01 -1.45402184e-04  1.31698757e-01  9.17841122e-03\n",
      "  -3.65520269e-02 -2.99647480e-01 -5.15292823e-01 -3.52479629e-02\n",
      "  -1.83192994e-02  1.03039369e-02 -1.58303306e-02 -3.12598348e-02\n",
      "   1.26795814e-04 -8.31198469e-02 -1.01107953e-03  1.19977631e-02\n",
      "  -1.64776653e-01 -1.05914390e-02  7.57835060e-02  8.88294261e-03\n",
      "   4.23479229e-01 -4.90148544e-01  1.32682279e-01 -2.50087138e-02\n",
      "  -5.30790150e-01  2.15595867e-02 -4.69458908e-01  9.00619198e-04\n",
      "  -2.97002196e-02  4.36439425e-01  4.05121781e-02  1.34762647e-02\n",
      "  -5.47835492e-02 -2.77848870e-01 -1.51492208e-01  1.28611520e-01\n",
      "  -2.41360776e-02  2.28205998e-03 -1.08596683e-01  2.40742955e-02\n",
      "  -1.17769511e-02  4.23401147e-01  7.81999081e-02  8.69804807e-03\n",
      "  -5.06112762e-02 -4.41933930e-01 -1.73874363e-01 -5.13383806e-01\n",
      "  -1.98675767e-02  1.12456949e-02 -5.23070022e-02 -1.55603662e-01\n",
      "   5.18350303e-03  2.79536366e-01  1.32823452e-01 -1.34519935e-01\n",
      "  -2.39612330e-02  8.19476973e-03  2.20306545e-01 -2.86072016e-01\n",
      "  -3.30684245e-01 -6.17560837e-03  2.72107869e-02 -5.50829386e-03\n",
      "  -1.26137200e-03  3.51107642e-02  1.48655858e-03 -2.61392713e-01\n",
      "  -7.43641779e-02 -3.78594398e-02  1.80514887e-01  3.12326908e-01\n",
      "   3.96490574e-01 -1.62309024e-03  1.56546012e-01  5.45157254e-01\n",
      "   3.57642048e-03  3.40834141e-01  1.23969510e-01  1.16712861e-02\n",
      "  -1.06166406e-02 -1.23958020e-02  9.44881700e-03 -1.04503483e-01\n",
      "  -1.83438793e-01 -6.17161319e-02  2.42821947e-02  3.52065444e-01\n",
      "   3.76567128e-03 -5.41821569e-02 -1.04844563e-01 -2.47120440e-01\n",
      "  -1.05900913e-01  1.24458279e-02 -4.11562651e-01  1.69869326e-02\n",
      "  -3.24009620e-02  1.23137422e-02 -2.83239603e-01 -3.99199165e-02\n",
      "   3.18223983e-02  3.31118032e-02 -1.50918914e-03  1.82380471e-02\n",
      "   1.36204176e-02 -1.76914170e-01  2.25285981e-02  1.95194669e-02\n",
      "   5.18383905e-02  1.98955536e-02  4.14019853e-01  2.99331963e-01\n",
      "  -1.76284425e-02 -1.21829985e-03  2.63792098e-01  5.21909026e-03\n",
      "  -1.06054015e-01 -1.00685991e-02 -7.86852324e-04 -1.10076480e-01\n",
      "  -2.97140241e-01 -3.95134948e-02  5.84498458e-02 -8.66912603e-02\n",
      "  -1.31197914e-01 -2.31588483e-01  2.55167395e-01 -1.37410723e-02\n",
      "   4.09152359e-03 -3.76742939e-03 -4.32907827e-02 -3.69617194e-02\n",
      "  -4.30334568e-01  1.05002224e-01 -5.40416630e-04 -3.40464681e-01\n",
      "  -4.40192908e-01  5.37443720e-03 -4.24823985e-02  1.56963523e-02\n",
      "   2.22583534e-03  3.76113947e-03 -3.57175209e-02  3.16389054e-02\n",
      "   4.00737584e-01  6.76732277e-03 -1.87142864e-01 -3.96146744e-01\n",
      "   3.71841043e-02 -3.26391794e-02 -9.48704605e-04 -1.28095686e-01\n",
      "   5.27212434e-02 -5.73671699e-01 -3.06306958e-01 -3.24442565e-01\n",
      "  -1.17022812e-01  1.37635857e-01  1.40901487e-02 -4.81819928e-01\n",
      "   1.94361731e-01 -1.58118382e-02  2.72143241e-02  5.71225882e-01\n",
      "   6.50082231e-02  2.04234989e-03 -9.57192387e-03 -4.56396639e-01\n",
      "  -2.13385168e-02 -5.07865191e-01  5.08650243e-01 -1.00559611e-02\n",
      "   5.14155217e-02 -5.32223210e-02  4.12541598e-01  1.38602201e-02\n",
      "   2.28358302e-02  6.66500581e-03  2.28326544e-01 -5.39770536e-03\n",
      "  -2.87914008e-01  2.54700296e-02  2.35558748e-02  2.88511198e-02\n",
      "   2.21174091e-01 -7.99525902e-03 -2.94356048e-01 -1.63653065e-02\n",
      "  -1.86907183e-02 -8.66598263e-03 -4.78568114e-02  2.01326516e-02\n",
      "   1.76401772e-02  2.30519578e-01  3.80031824e-01  1.94674470e-02\n",
      "  -1.81463528e-02  1.56415366e-02  1.16908988e-02  2.69921161e-02\n",
      "   4.60762769e-01  3.82708386e-02 -2.19985116e-02 -1.35317937e-01\n",
      "  -3.97208333e-01 -3.04047745e-02 -1.56064061e-02 -1.62056908e-02\n",
      "   1.68144852e-01  4.20778012e-03 -1.61039624e-02 -1.67931825e-01\n",
      "   4.72969353e-01  2.07781315e-01  4.48494069e-02  1.08430862e-01\n",
      "   5.31457216e-02  2.68472493e-01  2.31591184e-02  3.42631578e-01\n",
      "   2.00637966e-01 -1.83868334e-02 -1.55582756e-01 -1.33604221e-02]]\n",
      "Output of layer3: [[0.988618]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K# with a Sequential model\n",
    "for i in range(1,4):\n",
    "    get_layer_output = K.function([model.layers[0].input],[model.layers[i].output])\n",
    "    layer_output = get_layer_output([testRecord])[0]\n",
    "    print(f'Output of layer{i}:',layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "70hcisPuF-uK",
    "outputId": "0d3b0063-7023-4f95-f604-3f3600034973"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[28] #verifying the actual y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VK3AKG68HWnw"
   },
   "outputs": [],
   "source": [
    "!pip install -q wordcloud\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eELBMKP1GTM8",
    "outputId": "6c7feab2-acf1-4a70-e099-190c4c21a1cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02353219]]\n"
     ]
    }
   ],
   "source": [
    "#Lets submit our sample review on model and see outcome\n",
    "from nltk import word_tokenize\n",
    "from keras.preprocessing import sequence\n",
    "test=[]\n",
    "\n",
    "for word in word_tokenize( \"movie is trash and wasted my time\"):\n",
    "     test.append(word_index[word])\n",
    "test=sequence.pad_sequences([test],maxlen=maxlen,padding='post')\n",
    "prediction = model.predict(test)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rU7X3M3bIKqR",
    "outputId": "bbe8fcc0-1b19-4428-e2e3-01132875eb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review is negative\n"
     ]
    }
   ],
   "source": [
    "if (np.round(prediction) == 1):\n",
    "    print(\"Review is postive\")\n",
    "else:\n",
    "    print(\"Review is negative\")  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SeqNLP_SAnketShetye.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
